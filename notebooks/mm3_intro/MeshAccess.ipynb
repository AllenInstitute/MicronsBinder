{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    Import the key modules and set parameters\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caveclient import CAVEclient\n",
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "import cloudvolume \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CAVEclient('minnie65_public')"
    "# specify the materialization version, for consistency across time\n",
    "client.materialize.version = 117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "## What is a Mesh?\n",
    "A mesh is a set of vertices connected via triangular faces to form a 3 dimensional representation of the outer membrane of a neuron, glia or nucleus.\n",
    "\n",
    "### Meshes can either be static or dynamic:\n",
    "##### Static:\n",
    "- pros: smaller files thus easier to work with, multiple levels of detail (lod) which can be accessed (example below)\n",
    "- cons: may include false gaps and merges from self contacts, updated less frequently\n",
    "\n",
    "##### Dynamic:\n",
    "- pros: highly detailed thus more reflective of biological reality and backed by proofreading infrastructure CAVE (Connectome Annotation Versioning Engine)\n",
    "- cons: much larger files, only one level of detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graphene://https://minnie.microns-daf.com/segmentation/table/minnie65_public'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to access dynamic meshes, you can query the segmentation source from the info client\n",
    "client.info.segmentation_source()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: deduplication not currently supported for this layer's variable layered draco meshes\n"
     ]
    }
   ],
   "source": [
    "# this can be used to initialize a cloudvolume object\n",
    "cv = cloudvolume.CloudVolume(client.info.segmentation_source(), progress=False, use_https=True)\n",
    "# which, given a root_id, can be used to get a mesh\n",
    "# cloud volume returns a dictionary with the neuron segment id as the key \n",
    "# and the mesh as the value\n",
    "example_cell_id = 864691135474648896\n",
    "mesh = cv.mesh.get(example_cell_id)[example_cell_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1698627, 3), (3388543, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can check the size of the mesh like so\n",
    "# vertices are Nx3 x,y,z positions in nm\n",
    "# faces are Kx3 i,j,k indices into vertices that describe triangles\n",
    "mesh.vertices.shape, mesh.faces.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "Since downloading meshes can take some time, particularly for these dynamic meshes,\n",
    "it is convient to cache them on disk.     \n",
    "     \n",
    "To facilitate the analysis of meshes, we developed a package called MeshParty that we will use here to enable a cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to enable a cache, create a MeshMeta object\n",
    "mm = trimesh_io.MeshMeta(cv_path = client.info.segmentation_source(),\n",
    "                         disk_cache_path='minnie65_v117_meshes',\n",
    "                         map_gs_to_https=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "You can get a mesh like this and it will be cached in memory and in disk in case you need it again.    \n",
    "Restart the kernel and run the below cells again to see the difference.        \n",
    "You'll find the mesh file saved as an hdf5 file in the \"minnie65_v117_meshes\"\n",
    "subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = mm.mesh(seg_id=example_cell_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "The MeshParty object has more useful properties and attributes\n",
    "such as a scipy.csgraph sparse graph object (mesh.csgraph) and a networkx \n",
    "graph object (mesh.nxgraph) \n",
    "\n",
    "Read more about what you can do with MeshParty on its [Documentation](https://meshparty.readthedocs.io/en/latest/?badge=latest).\n",
    "\n",
    "In particular it lets you associate skeletons, and annotations onto the mesh into a \"meshwork\" object. \n",
    "    \n",
    "The meshes that are available in the visualization on micronsexplorer are faster because they are static and have been downsampled multiple times. However, this comes with the drawback of being less biologically accurate as stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can access one of these downsampled static meshes here:\n",
    "# note you need the use_https option here or else cloudvolume will try to use your google credentials\n",
    "# to access the bucket, and you don't have access to the bucket interface, just anonymous downloading\n",
    "cv = cloudvolume.CloudVolume(\"precomputed://gs://iarpa_microns/minnie/minnie65/seg\", use_https=True)\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cloud volume interface is the same but it is a faster initial download \n",
    "mesh = cv.mesh.get(example_cell_id)[example_cell_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2017003, 3), (3976580, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as you can see the meshes aren't exactly the same as before. They because they have not been downsampled\n",
    "mesh.vertices.shape, mesh.faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "In addition, the flat meshes are available in 3 levels of detail, this covers two orders of magnitude of detail\n",
    "which is what neuroglancer leverages to efficiently load the data at the resolution necessary to render the current scene.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lod 0: n_verts: 2017003 n_faces: 3976580\n",
      "lod 1: n_verts: 575851 n_faces: 1121653\n",
      "lod 2: n_verts: 101194 n_faces: 192476\n",
      "lod 3: n_verts: 23099 n_faces: 42211\n"
     ]
    }
   ],
   "source": [
    "for lod in range(4):\n",
    "    mesh = mesh = cv.mesh.get(example_cell_id, lod=lod)[example_cell_id]\n",
    "    print(f\"level of detail {lod}: n_verts: {mesh.vertices.shape[0]} n_faces: {mesh.faces.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
